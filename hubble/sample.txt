python input.py -u "https://quotes.toscrape.com/" -q "inspirational"


<?php
if ($_SERVER["REQUEST_METHOD"] == "POST") {
    $search_url = $_POST["search_url"];
    $search_query = $_POST["search_query"];

    // Replace this path with the correct absolute path to your Python interpreter
    $python_path = "C:\Users\Dell\AppData\Local\Programs\Python\Python311";

    // Replace this path with the correct absolute path to your input.py script
    $input_py_path = "C:\xampp\htdocs\hubble\backend input.py";

    // Use escapeshellarg to sanitize user input before passing it to the shell command
    $escaped_search_url = escapeshellarg($search_url);
    $escaped_search_query = escapeshellarg($search_query);

    // Construct the command to execute input.py
    $command = "$python_path $input_py_path --search_url $escaped_search_url --search_query $escaped_search_query";

    // Execute the input.py script with the user input
    exec($command);

    // Redirect to the search result page after processing the input
    header("Location: search-result.html");
    exit;
}
?>



import os
import csv
import sys
import mysql.connector

# ... (rest of the code)

# Function to save search results to CSV file
def save_search_results_to_csv(search_results):
    data_folder = 'datas'
    csv_filepath = os.path.join(data_folder, 'search_results.csv')

    with open(csv_filepath, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(['URL', 'Title'])
        writer.writerows(search_results)

# Function to perform a search query on the index
def search_webpages(search_query):
    data = fetch_data_from_mysql()

    if data is None:  # If data not available in MySQL, fallback to webpages.csv
        data = load_data_from_csv()

    if not data:
        print("No data found. Please run 'crawl.py' first to generate the data.")
        return

    processed_query = search_query.lower()

    found_results = []
    for url, title in data:
        if processed_query in title.lower():
            found_results.append((url, title))

    if found_results:
        # Sort the results based on the count of matched words in descending order
        ranked_results = sorted(found_results, key=lambda x: x[1].lower().count(
            processed_query), reverse=True)

        print("\nSearch Results:")
        for i, (url, title) in enumerate(ranked_results, 1):
            count_matched_words = title.lower().count(processed_query)
            print(f"{i}. URL: {url}")
            print(f"   Title: {title}")
            # print(f"   Matched Words: {count_matched_words}\n")
        
        # Save the search results to a CSV file
        save_search_results_to_csv(ranked_results)
        print("Search results saved to 'search_results.csv'")

    else:
        print("No matching results found.")

# ... (rest of the code)



--------------------------------------------------------------------------

import os
import csv
import sys
import mysql.connector

# ... (rest of the code)

# Function to save search results to CSV file
def save_search_results_to_csv(search_results):
    data_folder = 'datas'
    csv_filepath = os.path.join(data_folder, 'search_results.csv')

    with open(csv_filepath, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(['URL', 'Title'])
        writer.writerows(search_results)

# Function to perform a search query on the index
def search_webpages(search_query):
    data = fetch_data_from_mysql()

    if data is None:  # If data not available in MySQL, fallback to webpages.csv
        data = load_data_from_csv()

    if not data:
        print("No data found. Please run 'crawl.py' first to generate the data.")
        return

    processed_query = search_query.lower()

    found_results = []
    for url, title in data:
        if processed_query in title.lower():
            found_results.append((url, title))

    if found_results:
        # Sort the results based on the count of matched words in descending order
        ranked_results = sorted(found_results, key=lambda x: x[1].lower().count(
            processed_query), reverse=True)

        print("\nSearch Results:")
        for i, (url, title) in enumerate(ranked_results, 1):
            count_matched_words = title.lower().count(processed_query)
            print(f"{i}. URL: {url}")
            print(f"   Title: {title}")
            # print(f"   Matched Words: {count_matched_words}\n")
        
        # Save the search results to a CSV file
        save_search_results_to_csv(ranked_results)
        print("Search results saved to 'search_results.csv'")

    else:
        print("No matching results found.")

# ... (rest of the code)



--------------------------------------------------------------

if ($found_results) {
    // Start the loop from index 1 to skip the header row (URL, Title)
    for ($i = 1; $i < count($found_results); $i++) {
        $result = $found_results[$i];
        $url = $result["url"];
        $title = $result["title"];

        echo '<div>';
        echo '<h4>Search Result ' . $i . '</h4>';
        echo '<a href="' . $url . '">' . $url . '</a>';
        echo '</div>';
    }
} else {
    echo "No matching results found.";
}


------------------------------------------------------------

if ($found_results) {
    // Start the loop from index 1 to skip the header row (URL, Title)
    for ($i = 1; $i < count($found_results); $i++) {
        $result = $found_results[$i];
        $url = $result["url"];
        $title = $result["title"];

        echo '<div>';
        echo '<h4>' . $title . '</h4>'; // Display the actual title from the CSV file
        echo '<a href="' . $url . '">' . $url . '</a>';
        echo '</div>';
    }
} else {
    echo "No matching results found.";
}
